{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<H1> Leveling up with GenAI </H1>\n",
    "\n",
    "<h3> A Hands-On Workshop</h3>\n",
    "<br/>\n",
    "\n",
    "Cambridge Institute of Technology, Bangalore\n",
    "<br/> <br/>\n",
    "11th October 2024\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><u>Quick Introductions</u></h3>\n",
    "\n",
    "Ani Kannal - CEO and Founder @ Logos Labs <br/>\n",
    "BE Comp Sci from MS University, MS Comp Sci from SUNY Binghamton, <br/>\n",
    "Previously - VP of Engineering @ Deloitte, Founder CEO @ xcelerator.ninja <br/>\n",
    "<br/>\n",
    "Ninad Kulkarni - Sr. Consultant @ Logos Labs <br/>\n",
    "BE Electrical Engg from GTU, MS Embeded Systems from Technische Universit√§t Chemnitz, Germany<br/>\n",
    "Previously -  Product Engineer @ Stridely Solutions, Sr. Consultant @ HealthArk Insights<br/>\n",
    "<br/>\n",
    "Ajay S - Consultant @ Logos Labs <br/>\n",
    "BE Comp Sci from CIT Chennai<br/>\n",
    "Previously - Analyst @ HealthArk Insights</br></br>\n",
    "<b>Logos Labs</b> - Machine Learning and GenAI powered Product Engineering. <br/>\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>A few things before we start ...</h3>\n",
    "\n",
    "1. No sitting on the fence - be in it to win it!<br/>\n",
    "2. Stay sharp and engage actively - this is not a lecture.<br/>\n",
    "3. We dont have time for hand holding - this is a master class.<br/>\n",
    "4. GenAI is a rapidly evolving field - this session is not comprehensive.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>What is Prompt Engineering?</h3>\n",
    "\n",
    "Prompt engineering is the process of designing inputs, or prompts, to guide AI models to generate the desired outputs.<br/><br/>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/promptslab/Awesome-Prompt-Engineering/main/_source/prompt.png\" alt=\"isolated\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>What is your favourite tool?</h3>\n",
    "<img src=\"https://www.lifewire.com/thmb/WHlLZoymWDhBpNGrUi49kesDs5s=/750x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/ChatGPTInterface-95912d3e22404cf0a4ce6b6381d97432.jpg\" width=\"500\">\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kIGgHoze5AGX3sJ4Ik3wsA.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How do you write a good prompt?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://www.microsoft.com/en-us/education/blog/wp-content/uploads/2024/06/01-Microsoft-Classroom-Toolkit-Elements-of-a-Good-Prompt.webp\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>A Few Useful Resources</h3> <br/><br/>\n",
    "\n",
    "\n",
    "<b>Prompt Frameworks - </b><br/>\n",
    "https://medium.com/@slakhyani20/10-chatgpt-prompt-engineering-frameworks-you-need-to-know-41d4b76ed384 <br/><br/>\n",
    "\n",
    "\n",
    "<b>Advanced Prompt Engineering Techniques - </b><br/>\n",
    "https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How can our code talk to an LLM?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> We use APIs to talk to an LLM </h3>\n",
    "<br/>\n",
    "<img src=\"https://voyager.postman.com/illustration/diagram-what-is-an-api-postman-illustration.svg\" alt=\"isolated\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-google-genai duckduckgo-search youtube_search wikipedia langchainhub langchain_experimental numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b> You are going to need your own key for this workshop.</b>\n",
    "\n",
    "<b>Go to https://aistudio.google.com/ and generate your own Gemini API key.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# LLM API Key\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Now that you have your own API key, let's create a handle for the LLM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model - this is your handle to the LLM\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    #convert_system_message_to_human=True,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    handle_parsing_errors=True,\n",
    "    temperature=0.6,\n",
    "    # safety_settings = {\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    #     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    #     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    #     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Now that we have a handle on the LLM, let's try to call/invoke it with a prompt.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "response = llm.invoke(\"hi! how are you doing?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let's make one small tweak here - parameterize the prompt.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = f\"hi! my name is {{name}}, how are you doing?\"\n",
    "\n",
    "prompt = prompt_text.format(name=\"ani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> I want to generate a product description for each of the products in my product list - </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = [\"table fan\",\"soap box\",\"tooth brush holder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_prompt_text = f\"You are a copy writer that generates product descriptions that work best for marketting. Give me a product description for {{product}}\"\n",
    "\n",
    "product_prompt = product_prompt_text.format(product=product_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(product_prompt)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Still not very useful, but what if we use it in a loop?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions = {}\n",
    "\n",
    "for product_name in product_list:\n",
    "    product_prompt = product_prompt_text.format(product=product_name)\n",
    "    response = llm.invoke(prompt)\n",
    "    product_descriptions[product_name] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>BUT, there's a small problem...</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"what is my name?\")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>What are we missing?</h3>\n",
    "\n",
    "1. Memory - an LLM is purely transactional<br/>\n",
    "2. Context, Persona, Intent - an LLM has no consistent personality<br/>\n",
    "3. More than just text completion: Reasoning, Planning - an LLM cannot reason or plan<br/>\n",
    "4. Actions - an LLM is only for text completion, it cannot perform any actions<br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>We need an AGENT!</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>What are AI Agents?</h3>\n",
    "\n",
    "<b>Autonomous</b> entities capable of - </br></br>\n",
    "--   performing complex, multi-step tasks/actions, </br>\n",
    "--   maintaining state across interactions, and </br>\n",
    "--   dynamically adapting to new information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fagent-framework.ad7f5098.png&w=1920&q=75\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Different Libraries for Coding Agents</h3>\n",
    "\n",
    "* LangChain + LangGraph ‚Äî a mashup framework that contains almost all the LLM functionality out there. </br></br>\n",
    "* LlamaIndex ‚Äî LLM library (similar to LangChain) and its brand new Agents module LLamaAgents. </br></br>\n",
    "* CrewAI ‚Äî a library designed specifically for creating multiple Agents that can work together as a ‚Äúcrew‚Äù. </br></br>\n",
    "* AutoGen ‚Äî a library developed by Microsoft that comes with a low-code (almost no-code) interface AutoGen Studio. </br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3><u>ReAct Agents</u></h3>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TruhbBJ9asRGrvu9KIu62w.png\" width=\"800\">\n",
    "\n",
    "ReAct forces the model to output its response into explicit steps called ‚Äúthought‚Äù, ‚Äúaction‚Äù, and ‚Äúobservation‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counselor_prompt_text = '''You are a helpful career counsellor that provides advice and guidance on how prepare and apply for a job. You also help a candidate define a career path and provide guidance on how to pursue their career goals.\\n\\n\n",
    "\n",
    "Use the tools only when appropriate, otherwise you can answer as you see fit.\n",
    "Maintain a friendly tone.\n",
    "\n",
    "Always start by introducing yourself and asking for the user's name.\n",
    "\n",
    "Ask for the users education and experience along the way to make your advice more pertinent.\n",
    "\n",
    "Begin!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few tools\n",
    "from langchain_core.tools import tool, Tool\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.chains.llm_math.base import LLMMathChain\n",
    "\n",
    "\n",
    "\n",
    "ddg_search = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                func=problem_chain.run,\n",
    "                 description=\"Useful for when you need to answer questions about math. This tool is only for math questions and nothing else. Only input math expressions.\")\n",
    "\n",
    "# @tool\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two numbers.\"\"\"\n",
    "#     return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"searches the web for the provided query\"\"\"\n",
    "    return ddg_search.run(query)\n",
    "\n",
    "tools = [search, math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a memory store\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm, tools, checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=counselor_prompt_text)]}, config\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"My name is Ani. what can you do for me?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Great! Let's start applying for a job.\")]}, config\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the typical salary for a prompt engineer?\")]}, config\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the lim of 1/x as x tends to 0?\")]\n",
    "\n",
    "for event in agent.stream({\"messages\": messages}, config):\n",
    "    for v in event.values():\n",
    "        v['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>So, What does our agent look like?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's look at an alternate method to create an agent ... </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternate example ##\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.agents.initialize import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "\n",
    "## CREATE A FEW TOOLS ##\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(name=\"Wikipedia\",\n",
    "                      func=wikipedia.run,\n",
    "\t              description=\"A useful tool for searching the Internet to find information on world events, issues, dates, years, etc. Worth using for general topics. Use precise questions.\")\n",
    "\n",
    "problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                func=problem_chain.run,\n",
    "                 description=\"Useful for when you need to answer questions about math. This tool is only for math questions and nothing else. Only input math expressions.\")\n",
    "\n",
    "word_problem_template = \"\"\"You are a reasoning agent tasked with solving \n",
    "the user's logic-based questions. Logically arrive at the solution, and be \n",
    "factual. In your answers, clearly detail the steps involved and give the \n",
    "final answer. Provide the response in bullet points. \n",
    "Question  {question} Answer\"\"\"\n",
    "\n",
    "math_assistant_prompt = PromptTemplate(input_variables=[\"question\"], template=word_problem_template)\n",
    "\n",
    "word_problem_chain = LLMChain(llm=llm, prompt=math_assistant_prompt)\n",
    "\n",
    "word_problem_tool = Tool.from_function(name=\"Reasoning Tool\",\n",
    "                                       func=word_problem_chain.run,\n",
    "                                       description=\"Useful for when you need to answer logic-based/reasoning questions.\",)\n",
    "\n",
    "\n",
    "## INITIALIZE AN AGENT ##\n",
    "\n",
    "agent_2 = initialize_agent(\n",
    "    tools=[wikipedia_tool, math_tool, word_problem_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_2.invoke(\n",
    "    {\"input\": \"what can you do?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(agent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We can create the graph from scratch using LangGraph</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from typing import TypedDict\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "## Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "## Add nodes to the graph\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "## Add edges to the graph\n",
    "workflow.add_edge(START, \"agent\")   \n",
    "workflow.add_edge('agent', END)\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Runnable\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=counselor_prompt_text)]},\n",
    "    config={\"configurable\": {\"thread_id\": 1}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what can you do for me?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 1}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Case Studies</h3>\n",
    "\n",
    "1. Counselor Bot</br></br>\n",
    "2. AI Mentor</br></br>\n",
    "3. Deynamic web scraper </br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Logistics</h3>\n",
    "\n",
    "| | <h4>Monday</h4> | <h4>Tuesday </h4>| <h4>Wednesday</h4> |\n",
    "|--------|---------|---------|---------|\n",
    "| <h4>Morning</h4> | Workshop | Prompt Design and Testing - </br> Test your hypothesis</br></br>**Checkpoint 2** | Finalize Project |\n",
    "| <h4>Afternoon</h4> | Ideation and Execution Plan - </br>Finalize your problem statement, </br>define the solution strategy, </br>create an execution plan|Create the solution POC|**Checkpoint 4**|\n",
    "| <h4>Evening</h4> | **Checkpoint 1** | **Checkpoint 3** | Demos and Presentations!|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Final Presentations</h3>\n",
    "\n",
    "1. Start with a short presentation</br></br>\n",
    "-- problem statement</br>\n",
    "-- proposed solution</br>\n",
    "-- what's in scope and what's not</br>\n",
    "-- solution architecture\n",
    "</br></br>\n",
    "\n",
    "2. Show a working demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
